{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Download Sentiment Dataset**"
      ],
      "metadata": {
        "id": "E_Guin6-ct-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -Uq datasets evaluate accelerate"
      ],
      "metadata": {
        "id": "s5LPXkHbhznR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip uninstall -y wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyFALq-LQfq8",
        "outputId": "c83f2fa6-f94c-4607-c261-63f8061963d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping wandb as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "sentiment_dataset = load_dataset(\"rasyosef/amharic-sentiment\")\n",
        "sentiment_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoqmmemFydO1",
        "outputId": "a25789ce-d8e4-4877-8173-2352278b675c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:86: UserWarning: \n",
            "Access to the secret `HF_TOKEN` has not been granted on this notebook.\n",
            "You will not be requested again.\n",
            "Please restart the session if you want to be prompted again.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['clean_tweet', 'label'],\n",
              "        num_rows: 2223\n",
              "    })\n",
              "    dev: Dataset({\n",
              "        features: ['clean_tweet', 'label'],\n",
              "        num_rows: 279\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['clean_tweet', 'label'],\n",
              "        num_rows: 279\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_dataset[\"train\"].features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbCb0imbzrIF",
        "outputId": "e18611fb-7005-48cd-b270-9990198aba6b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clean_tweet': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['negative', 'positive'], id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = sentiment_dataset[\"train\"].features[\"label\"].names\n",
        "label_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3deWqBSNzxsn",
        "outputId": "2933e43b-12e4-425f-b857-95b9a5ed3d5f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['negative', 'positive']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tokenize Tweets**"
      ],
      "metadata": {
        "id": "Cv2DfPGxmulq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_id = \"Davlan/afro-xlmr-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "print(tokenizer.tokenize(\"áŠ¨áˆ€áŒˆáˆ«á‰¸á‹ áŠ¨áŠ¢á‰µá‹®áŒµá‹« áŠ¨á‹ˆáŒ¡ áŒáˆ›áˆ½ áˆá‹•á‰° <mask> á‰°á‰†áŒ¥áˆ¯áˆá¢\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg0Iq8gBm1e5",
        "outputId": "bcb6eaf5-7ab0-40fe-8916-69d0241949a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['â–áŠ¨', 'áˆ€', 'áŒˆ', 'áˆ«á‰¸á‹', 'â–áŠ¨áŠ¢á‰µá‹®áŒµá‹«', 'â–áŠ¨', 'á‹ˆáŒ¡', 'â–', 'áŒáˆ›áˆ½', 'â–', 'áˆá‹•', 'á‰°', ' <mask>', 'â–á‰°', 'á‰†', 'áŒ¥', 'áˆ¯áˆá¢']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_dataset(samples):\n",
        "  tokenized_samples = tokenizer(samples[\"clean_tweet\"], truncation=True, max_length=512)\n",
        "  return tokenized_samples\n",
        "\n",
        "tokenize_dataset({\"clean_tweet\":[\"áŠ¨áˆ€áŒˆáˆ«á‰¸á‹ áŠ¨áŠ¢á‰µá‹®áŒµá‹« áŠ¨á‹ˆáŒ¡ áŒáˆ›áˆ½\"]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K4TDK_smYF9",
        "outputId": "f362d7e2-87b0-40d0-ee83-6ee049193ae9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[0, 1464, 21608, 5430, 66052, 165627, 1464, 87365, 6, 230446, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_datasets = sentiment_dataset.map(\n",
        "    tokenize_dataset,\n",
        "    batched=True,\n",
        "    remove_columns=[\"clean_tweet\"]\n",
        "  )\n",
        "preprocessed_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW5DAkztoyzH",
        "outputId": "2fda6b41-c385-4d29-f87b-b202a9400dd9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 2223\n",
              "    })\n",
              "    dev: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 279\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 279\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Amharic BERT model**"
      ],
      "metadata": {
        "id": "jP7R35bNq5-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id2label={i: label for i, label in enumerate(label_names)}\n",
        "label2id={label: i for i, label in enumerate(label_names)}\n",
        "\n",
        "print(id2label, label2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQCDsP_hsKgT",
        "outputId": "456c1f79-dd5b-42d8-9d32-9a620c29465d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'negative', 1: 'positive'} {'negative': 0, 'positive': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=len(label_names),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    # device_map=\"cuda\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRIgwPh_pztu",
        "outputId": "3f412930-b0c8-4d53-a2f9-f336bbe07f11"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at Davlan/afro-xlmr-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Finetuning**"
      ],
      "metadata": {
        "id": "ncGTp5y2tCdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "q62avVBzsZ0d"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 3\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_id+\"-finetuned\",\n",
        "    learning_rate=2e-5,\n",
        "    # lr_scheduler_type=\"linear\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=epochs,\n",
        "    weight_decay=0.1,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    # load_best_model_at_end=True,\n",
        "    # metric_for_best_model=\"f1\",\n",
        "    fp16=True,\n",
        "    seed=42,\n",
        ")"
      ],
      "metadata": {
        "id": "fwru3t0bt_2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a74a7eb-38e5-4d85-f3aa-d33d28524b6b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "  metric1 = evaluate.load(\"accuracy\")\n",
        "  metric2 = evaluate.load(\"precision\")\n",
        "  metric3 = evaluate.load(\"recall\")\n",
        "  metric4 = evaluate.load(\"f1\")\n",
        "\n",
        "  logits, labels = eval_preds\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "  accuracy = metric1.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "  # precision = metric2.compute(predictions=predictions, references=labels, average='macro')[\"precision\"]\n",
        "  # recall = metric3.compute(predictions=predictions, references=labels, average='macro')[\"recall\"]\n",
        "  # f1 = metric4.compute(predictions=predictions, references=labels, average='macro')[\"f1\"]\n",
        "\n",
        "  return {\n",
        "      \"accuracy\": accuracy,\n",
        "      # \"precision\": precision,\n",
        "      # \"recall\": recall,\n",
        "      # \"f1\": f1\n",
        "  }\n",
        "\n",
        "compute_metrics((np.array([[1,0], [0,1]]), np.array([0,1])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGU1-lE2vebs",
        "outputId": "269c1233-cb2c-4fa8-b1b6-4060790d9656"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=preprocessed_datasets[\"train\"],\n",
        "    eval_dataset=preprocessed_datasets[\"dev\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "3SgipS5LxJtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61fe5f8a-273e-4d7c-ad3f-0b2900248d5c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-b0b54413edf8>:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "vQUu-msQ1_0I",
        "outputId": "06b23f77-2ccb-4638-e70b-faddc7a049ee"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.7379811406135559,\n",
              " 'eval_model_preparation_time': 0.0089,\n",
              " 'eval_accuracy': 0.5376344086021505,\n",
              " 'eval_runtime': 6.523,\n",
              " 'eval_samples_per_second': 42.772,\n",
              " 'eval_steps_per_second': 1.38}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "Rro_9eUF2CJA",
        "outputId": "810fb03c-fc32-4539-c1fe-9a8e4315e71f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [210/210 06:45, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Model Preparation Time</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.517800</td>\n",
              "      <td>0.328802</td>\n",
              "      <td>0.008900</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.356600</td>\n",
              "      <td>0.341656</td>\n",
              "      <td>0.008900</td>\n",
              "      <td>0.892473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.260700</td>\n",
              "      <td>0.328719</td>\n",
              "      <td>0.008900</td>\n",
              "      <td>0.896057</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:47]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=210, training_loss=0.37836009434291296, metrics={'train_runtime': 406.5334, 'train_samples_per_second': 16.405, 'train_steps_per_second': 0.517, 'total_flos': 1025914457105496.0, 'train_loss': 0.37836009434291296, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "zY8apvbx76GW",
        "outputId": "b8850056-77e4-4ce0-a322-560712b38a6a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.3287185728549957,\n",
              " 'eval_model_preparation_time': 0.0089,\n",
              " 'eval_accuracy': 0.8960573476702509,\n",
              " 'eval_runtime': 6.0543,\n",
              " 'eval_samples_per_second': 46.083,\n",
              " 'eval_steps_per_second': 1.487,\n",
              " 'epoch': 3.0}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluate Model**"
      ],
      "metadata": {
        "id": "JIi7JNlx68TL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "num_samples = len(preprocessed_datasets[\"test\"])\n",
        "inputs = data_collator([preprocessed_datasets[\"test\"][i] for i in range(num_samples)])\n",
        "# print(inputs)\n",
        "\n",
        "y_pred = []\n",
        "\n",
        "#output = model(**inputs)\n",
        "for i in range(0, len(inputs[\"input_ids\"]), 5):\n",
        "  output = model(**{k: v[i:i+5].to(\"cuda\") for k, v in inputs.items()})\n",
        "  y_pred.extend(np.argmax(output.logits.tolist(), axis=-1))\n",
        "\n",
        "y_test = np.array(preprocessed_datasets[\"test\"][\"label\"])\n",
        "\n",
        "print(y_pred)\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIVaUrTm2MXD",
        "outputId": "faa16006-ab29-400a-ca82-7c86c574a9df"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]\n",
            "[1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1\n",
            " 0 1 1 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 0 0 1 0\n",
            " 0 1 0 1 1 0 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 1 1 1 1 0 1\n",
            " 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0\n",
            " 0 1 0 1 1 0 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0\n",
            " 1 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 1 1 1\n",
            " 0 0 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0\n",
            " 1 0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "metrics.confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "pb-tehHs71zg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037e853c-abae-40d3-bdbb-2f681648d48a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[130,  20],\n",
              "       [ 20, 109]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "t9zfLF5p8Sqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594bc7cf-513d-4dd6-e978-e57633b6ba9e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.87      0.87       150\n",
            "           1       0.84      0.84      0.84       129\n",
            "\n",
            "    accuracy                           0.86       279\n",
            "   macro avg       0.86      0.86      0.86       279\n",
            "weighted avg       0.86      0.86      0.86       279\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test in Pipeline**"
      ],
      "metadata": {
        "id": "zz1n-9P-sVls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
        "pipe(\"á‰†áŠ•áŒ† áŠáˆáˆ áŠá‹\")"
      ],
      "metadata": {
        "id": "CeI9CeUwsamR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fc11aa5-0a10-4fdf-ceff-948eaed2591c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'positive', 'score': 0.9790157079696655}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"áŠ áˆªá áˆá‰¥áˆµ\")"
      ],
      "metadata": {
        "id": "10KPQ8e9s16w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74014b1-009a-4f75-c0bd-8b45aef1e9c5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'positive', 'score': 0.8144221305847168}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"áŒ…áˆ‹áŠ•á\")"
      ],
      "metadata": {
        "id": "i84DslUCs-oY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e8e40a-6c7e-4327-9991-06ad2bda8c56"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'negative', 'score': 0.8327473402023315}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"áŠ¥á‹šáˆ… áˆ°áˆáˆ­ á‰ áˆ›á‰³ áˆ˜áŒ“á‹ áŠ¥áˆáˆ«áˆˆáˆ\")"
      ],
      "metadata": {
        "id": "ktEKYGhCtBLC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "389936b6-f740-4e45-a483-5c331225b369"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'negative', 'score': 0.8777390122413635}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"á‹©áŠ­áˆ¬áŠ• áŠ¥áŠ“ áˆ©áˆµá‹« áŠ¨á‰£á‹µ á‹áŒá‹« áˆ‹á‹­ áŠ“á‰¸á‹\")"
      ],
      "metadata": {
        "id": "SEThuPFCwOuz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a20b6e-5a06-42a6-a821-d440a7c2c1e0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'negative', 'score': 0.8125700354576111}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mis-classified**"
      ],
      "metadata": {
        "id": "1IZvMcFjFvfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "misclassified = []\n",
        "for i in range(len(y_pred)):\n",
        "  if y_pred[i] != y_test[i]:\n",
        "    misclassified.append(i)\n",
        "\n",
        "print(misclassified)"
      ],
      "metadata": {
        "id": "e0YF7s0p2YdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70715b27-5074-4201-ca76-5735228e86cc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12, 13, 23, 25, 29, 33, 41, 59, 63, 65, 67, 71, 81, 89, 95, 99, 100, 103, 107, 115, 120, 123, 125, 144, 146, 147, 150, 173, 192, 203, 210, 211, 219, 220, 239, 243, 249, 250, 256, 261]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in misclassified:\n",
        "  input_ids = preprocessed_datasets[\"test\"][idx][\"input_ids\"]\n",
        "  label = preprocessed_datasets[\"test\"][idx][\"label\"]\n",
        "  print(label, tokenizer.decode(input_ids))"
      ],
      "metadata": {
        "id": "0JvMqYDOFzti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08cf1fd-c1a7-4a56-fd1b-ef763d54ce89"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 <s> áŠ¥áŠ•á‹²áˆ… áŠ á‹­áŠá‰µ áˆ­á‹•áˆµ áŒ½á áˆˆá‰ á‹áˆ á‹­áŒ á‰¥á‰áŠ• á‹µáŠ•áŒáˆ­áŒáˆ­ á‹­áˆ‹áˆ áŒáŠ• áŠ áˆ»áˆ á‰ á‰ á‹“áˆáˆ áŠ áˆá‰€áˆá‹µáˆ áŠ«áˆˆ áˆáŠ• á‹­á‹°áˆ¨áŒ? ğŸ˜ƒ áˆµáˆœáŠáˆ… áŠ á‹«áˆŒá‹áŠ“ áˆ±áˆ«áŒáˆ áˆ²áŒ á‹­á‰ áŠ¥áŠ•áŠ³áŠ• á‰¥áŠ•áˆ°áˆ› á‹­áˆ»áˆˆáŠ“áˆ á‰ á‹áŠá‰µá¢</s>\n",
            "0 <s> áŠ¨áŠ¥áŠ•á‹° áŠ áŠ•á‰° áŠ á‹­áŠá‰± á‹°á‹°á‰¥ áˆ˜áˆ€á‹­áˆ áŒ­áˆ«á‰… á‹¨áˆáŠ•áˆ‹á‰€á‰…á‰ á‰µ á‹˜áˆ˜áŠ• á‹­áˆáŠ•!!! áˆáˆŒáˆ áŠ á‰¥á‹¨á‹¨á‹¨á‹¨</s>\n",
            "0 <s> áˆ°áˆŠ áŠ¥á‹áŠá‰µ áŠ áŠ•á‰º áŠ áˆ›áŠ áŠáˆ½ áŠ¨á‹šáˆ… áˆ‚áŒ‚ğŸ˜„</s>\n",
            "0 <s> áˆáŠ­ á‰¥áˆˆáˆƒáˆá¢ áŠ¥áŠ›áˆ› á‰°á‰°á‰¥á‰µá‰ áŠ“áˆá¢</s>\n",
            "0 <s> á‹«áˆ°á‰¥áŠ¨á‹ áˆáˆ‰ á‹­áˆ³áŠ«! á‰ áŠ¥á‹áŠá‰µáŠ“ áŠ¥á‹á‰€á‰µáŠ“ á‰ á‰°áˆ˜áˆ°áˆ¨á‰µáˆ­á‹ áˆ«á‹•á‹­ á“áˆ­á‰² áŠ¢á‰µá‹®áŒµá‹«áŠ“ áˆ…á‹á‰¦á‰½á‹‹ á‰³ááˆ¨á‹áŠ“ á‰°áŠ¨á‹áˆ¨á‹ á‹­áŠ–áˆ«áˆ‰á¢</s>\n",
            "0 <s> áŠ áŒ‹áŠ•áŠ•á‰¶á‰½ áŠááˆ´áŠ• á‹­áˆ˜áŒˆá‰£áˆ‰á¢ áˆ˜áˆªá‹¬áŠ• áŠ áŒˆáˆˆáŒáˆ‹áˆˆáˆ á¡á¡ áŠ¥áŠ” áŠááˆ³á‰µáŠ• áŠ áˆ˜áŒ£áˆˆáˆ</s>\n",
            "0 <s> áŠ¥á‹áŠá‰µ áŠ¥áŠ•áŠáŒ‹áŒˆáˆ­ áŠ¨á‰°á‰£áˆˆ áˆ¹áˆ˜á‰µ áŠ¨áˆáŠ•áˆˆá‹ áˆ¹áˆá‰µ á‰¥áŠ•áˆá‹ áŠ á‹­áˆ»áˆáˆ? áŠ áŠ•á‹µ á‰ á‹ˆá‰³á‹°áˆ«á‹Š áˆ³á‹­áŠ•áˆµ áŠ¨áá‰°áŠ› áŒ€áŠáˆ«áˆáŠ• áŠ¥áŠ•á‹²áˆ áŠ¨áˆ˜áŒ£áˆ áŠ«áˆáˆ†áŠ á‰ áŠ­á‰¥áˆ­ á‰ áŒ¡áˆ¨á‰³ áˆ›áŒáˆˆáˆ áŠ á‹­áˆ»áˆáˆ ? áŒ¥á‹á‰°áŠ› áŠ á‹­á‹°áˆ‰áˆ áŠ¨á‰°á‰£áˆˆ á‹°áˆá‹›á‰¸á‹áŠ• áŠ¨ááˆ á‹­á‰…áˆ­á‰³ áŒ á‹­á‰† áˆ˜áˆ˜áˆˆáˆµ áŠá‰ áˆ­ğŸ’šğŸ’›â¤ï¸</s>\n",
            "0 <s> áŠ¨áˆ€áŒˆáˆ¬á‹ á‹­áˆá‰… áˆˆá‰»á‹­áŠ“á‹‰á‹«áŠ• áˆá‰¹ á‹¨áˆ†áŠá‰½ áˆ€áŒˆáˆ­ ğŸ™ƒ...</s>\n",
            "0 <s> á‰°á‹‹ğŸ˜„ áŠ¥áŠ” áˆˆáˆƒáŒˆáˆªá‰· áˆµáˆˆá‰µáˆáˆ…á‰µ á£ áˆ°áˆ‹áˆá£ áŒ¤áŠ“ á£ áˆ˜áˆ°áˆ¨á‰° áˆáˆ›á‰µ á£ á‹áŒ­ áŒ‰á‹³á‹­ á‹ˆá‹˜á‰°... á‹­áˆ„áŠ• á–áˆŠáˆ² á‹­á‹¤ áˆ˜áŒ¥á‰»áˆˆáˆ á‹¨áˆšáˆ á‹¨á“áˆ­á‰²á‹á‰½ á‹ˆáŒ áŠá‹ á‹¨áŠ“áˆá‰€áŠá¢ á‰¢á‹«áŠ•áˆµ áŠ¥áŠ•á‹°áˆ›áˆ…á‰ áˆ¨áˆ°á‰¥ á‹¨á–áˆˆá‰²áŠ« áŠ•á‰ƒá‰³á‰½áŠ•áŠ• á‹­áŒ¨áˆáˆ­áˆáŠ“áˆá¢ á‰£áŠ•áˆµáˆ›áˆ›áˆ á‹á‹­á‹­á‰µ áˆ˜áˆáˆ˜á‹µ áŠ áˆˆá‰¥áŠ•á¢</s>\n",
            "1 <s> áŠ¦áˆ®áˆá‹« á‹¨á‹°áŒ‹áŒˆá‹á‰½ áŠ áŒˆáˆ­ áŠ“á‰µ áŠ¥áŠ•áŒ‚ áŠ áŒ‹á‰½ á‰³áŒ‹á‰½ á‹²áˆ«áˆ› á‹¨áˆšáŠ«áˆ„á‹µ á‰ á‰µ áŠ­áˆáˆ áŠ á‹­á‹°áˆˆáˆ</s>\n",
            "1 <s> ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£ áŠ¥áˆº áŒáˆªá‹¬ áˆ¾áˆš áˆˆáˆ˜á‰€áŒ£á‰µ á‹áŒáŒ áŠáŠ</s>\n",
            "0 <s> áŠáŒˆáˆ­ ááˆˆáŒ‹ á‰ á‰ƒ áŠ áˆªá áˆšá‹«áˆµá‰¥áˆ áˆáˆµáˆáˆ½ áŠá‹ áŠ á‹­á‹°áˆ áˆ˜áˆµááŠ”</s>\n",
            "1 <s> áˆˆáˆ˜áˆáŠ«áˆ á‹•á‹µáˆáˆ²áˆ á‰ áŠ á‹áˆ®á•áˆ‹áŠ• áˆá‰°áˆ­ á‹áˆµáŒ¥ áˆ³áŠ•á‰²áˆ á‹¨á‹ˆáˆ¨á‹ˆáˆ¨á‹ áŒáˆˆáˆ°á‰¥ á‰°á‰€áŒ£! áˆ‰ á‹¨á‰°áˆ³á‹áˆªá‹áŠ• áŠ¥áŠ•á‰…áˆµá‰ƒáˆ´áŠ• á‰ áˆ›á‹ˆáŠ­ á‰ áˆšáˆ á‰ á–áˆŠáˆµ áˆˆ10á‰€áŠ“á‰µ á‰ áŠ¥áˆµáˆ­ á‰†á‹­á‰¶ áŒ‰á‹³á‹© á‰ áˆ²á‰ªáˆ áŠ¬áˆµ á‰³á‹­á‰¶ áŠ«áˆ³ 17,600 á‹¶áˆ‹áˆ­ áŠªáˆ³áˆ« áŠ¥áŠ•á‹²áŠ¨ááˆ áŠ áˆµáˆ¨á‹µá‰·áˆ!</s>\n",
            "1 <s> á…áŠ•áˆáŠ› á‹áŠ– á‹¨áˆšá‰£áˆ á‹¨áˆˆáˆ ğŸ¤·ğŸ¾ â™€ï¸áŠ¥á‹›á‹ á‹ˆá‹°á‹šá‹« áŒ‰á‹³á‰¹áˆ áŠ¥á‹¨á‹ˆáŒ£ áŠá‹ áˆá‹µáˆ¨ áˆ°á‹ á‰ áˆ‹ áŠ á‹áˆ¬á‹á‰½ áˆ˜áˆµáŒŠá‹µ áŠ á‰ƒáŒ¥áˆ‹á‰¹ áŠ áˆ›áˆ«á‹áŠ• áˆˆáˆ›á‰£áˆ‹á‰µ áˆˆá‹›áˆ¬ áŠ áˆá‰°áˆ³áŠ«áˆ áŒ¥á‰ áŠ¨á‹šáˆ… áˆ˜áˆ­á‹</s>\n",
            "1 <s> á‹­áˆ…áŠ• á‹¨áŠáŒˆáˆ¨áˆ… áˆ°á‹ áˆáˆ‰áˆ áˆ°á‹ á‹¨áˆšáŠ–áˆ¨á‹ áŠ¥áˆ­áˆ± áŠ¥áŠ•á‹°áˆšá‹«áˆáˆ˜á‹ áˆµáˆˆáˆšáˆ˜áˆµáˆˆá‹ áŠá‹á¢ á‰¤á‰°áŠ­áˆ­áˆµá‰²á‹«áŠ• áˆ›áˆ­á‹«áˆáˆ áŒŠá‹®áˆ­áŒŠáˆµáˆ áŠ¥á‹¨á‹°áˆ¨áˆµáŠ­ áˆ³á‰µáˆ˜áŒ£ áŠ á‰µá‰€áˆ­áˆ á‰¥á‹¬ áŠ¥áŒˆáˆá‰³áˆˆáˆá£ á‰ áˆ€áˆ°á‰µ áŠ á‰µáˆ˜áˆµáŠ­áˆ­ á‹¨áˆšáˆˆá‹áŠ• áŠ á‰¥áˆ‹áˆ‹á‹á¢</s>\n",
            "1 <s> 2)áˆˆáˆ•áŒˆá‹ˆáŒ¥áˆ áˆ˜áŠ•áŒˆá‹µ á‰ áˆ­ áŠ¥á‹¨áŠ¨áˆá‰° áŠá‹ á‹¨áŒá‰£á‰³ áˆá‰ƒá‹µ áˆˆá‹µáˆ­áŒ…á‰µ áˆˆáŠ•áŒá‹µ á‰°á‰‹áˆ›á‰µ áŠ áˆ¥áˆáˆ‹áŒŠ áŠá‹ áŒáŠ•á‰£á‰³á‹ á‰ áŠ áŒ­áˆ­ áŒŠá‹œá‰£áˆˆáˆ˜áŒ áŠ“á‰€á‰ áˆáŒˆáˆ­ áŠ¨áˆšá‹«áˆ˜áŠáŒ¨á‹ áŠ¢áŠ®áŠ–áˆš á‰³áŒ£áˆˆá‰½ áˆ˜áŠ–áˆªá‹« á‰¤á‰µ á‰°áˆ á‰£áˆˆáˆ˜áˆ¥áˆ«á‰± á‰ áŠªáˆ«á‹­ á‹°áˆ¨áŒƒ á‰£áˆáŒ á‰ á‰€ áŠ áˆˆáˆ˜áŠ–áˆ© áŒáˆˆáˆ á‰¡áŠ• áŠá‹ á‹¨áˆšáŒá‹³</s>\n",
            "0 <s> áŠ áˆœáŠ• áŠ£áˆœáŠ• áŠ£áˆœáŠ• á¢</s>\n",
            "0 <s> : áŠ¨á–áˆˆá‰²áŠ¨áŠá‰½ á‹¨áˆáŠ•áŒ á‰¥á‰€á‹áŠ• á‹˜áˆ‹á‰‚ á‰³áˆ›áŠáŠá‰µ áŠ áŠ•á‹³áŠ•á‹± áˆ•áˆáˆ á‰¥á‰» áˆ²á‹«á‹°áˆ­áŒá‰¥áŠ• áˆˆáŒ‹áˆ« áŠ áˆ‹áˆ› áŠ¨áá‰°áŠ› á‹¨áŒáˆ áˆ˜áˆµá‹‹á‹•á‰µáŠá‰µ áŠ¥á‹¨áŠ¨áˆáˆ‰ á‹«áˆ‰ áˆ˜áŠ–áˆ«á‰¸á‹áˆ áŒáˆá… áŠ¥á‹¨áˆ†áŠ áŠá‹:: áŠ¥áŠ› áˆ...</s>\n",
            "1 <s> á‰µáŒáˆ«á‹­áŠ“ áˆ…á‹ˆáˆ“á‰µ áˆˆá‹«á‹­á‰¶ áˆ›á‹¨á‰± á‹­áˆ»áˆ‹áˆá¡ á‹°áˆ á‹­áˆ„áŠ•áŠ• áŒ‰á‹³á‹­ áŠ­áˆáˆ‰áŠ• áˆˆáˆ›áŒ¥á‰ƒá‰µ áŠá‹á¢ áˆ˜áˆµáˆ›áˆ›á‰µ áŠ¥áŠ•á‹³áˆˆ áˆ†áŠ– áŠ áˆˆáˆ˜áˆµáˆ›áˆ›á‰µ should be acceptable. áˆŒáˆ‹á‹ á‰€áŒ£á‹© áˆáˆ­áŒ« áˆšáˆá‰³á‹ áŒ‰á‹³á‹­ áŠá‹á¡ áŠ­áˆáˆ‰áŠ• áˆˆáˆ˜áŒ‰á‹³á‰µáŠ“ áˆ…á‹á‰¡áŠ• áˆˆáˆ›áˆ³á‰€á‰… á‹¨áˆšá‹°áˆ¨áŒ áˆµáˆ« áŒáŠ• áˆ˜á‰†áˆ áŠ áˆˆá‰ á‰µ</s>\n",
            "1 <s> \"áŠ áˆáŒˆáˆáˆ…áˆáŠ• áˆáŠ• áŠ áˆ˜áŒ£á‹\" á‹­áˆ‹áˆ á‹«áŒˆáˆ¬ áˆ°á‹</s>\n",
            "0 <s> áˆˆáŠ¥áŠáˆ± áˆáˆ­áŒ¥ á‹¨áŠ­áˆ­áŠ­áˆ­ áˆ˜áˆáˆµ áŠ áˆˆáŠ - \"á‹áŠ©!\" :-)</s>\n",
            "0 <s> á‹¨á‹ˆáˆµáˆ‹á‰³á‹á‰½ áˆ›áŒ­á‰¥áˆ­á‰ áˆ­ áˆ˜á‰¼áˆ áŠ á‹­áˆ áˆ«áˆ! á‹µáˆ…áŠá‰µáŠ• áˆ›áˆ¸áŠá‰áŠ• á‰ áŠ¥áŒá‹šáŠ á‰¥áˆ”áˆ­ áá‰ƒá‹µ áˆµáˆˆáˆ†áŠ áˆ›áŠ•áˆ áˆŠá‹«á‰†áˆá‰¥áŠ• áŠ á‹­á‰½áˆáˆ! áŒá‹µá‰¡ á‹¨áŠ¢á‰µá‹®áŒµá‹­ á‰ áŠ¢á‰µá‹®áŒµá‹« áˆ˜áˆ†áŠ‘ á‰ áˆ›áŠ•áˆ áˆŠáŠ«á‹µ áŠ á‹­á‰½áˆáˆ! áŠ¨áˆáŠ¨áˆ©áˆ á‹á‹µá‰… áˆ˜áˆ†áŠ‘ áŒ¥áˆ­áŒ¥áˆ­ á‹¨áˆˆáŠáˆ!</s>\n",
            "0 <s> \"áŠ«á‰€á‹µáŠá‹ á‰ áˆ‹á‹­ á‰³áŒ‹á‰½ á‹«áˆ¥áˆá‰³áŠ• á‰¢áˆ†áŠ•áˆ áŠ¨áŠ¥á‰…á‹³á‰½áŠ• áŒ‹ á‹­áˆ áŠ“áˆ áˆ á‹˜áŠ•á‹µ áŠ áŠ•á‹³áŠ•á‹¶á‰¹áŠ• áˆ˜áˆáˆ áŠ• áˆˆáŠ áŒ‹á‰¾á‰¹ áˆ áŒ¥á‰°áŠ“áˆ!\" á‹ˆá‹­á‹˜áˆ® áŠ•áŒ‰áˆ¡ áŒ¥áˆ‹áˆáŠ•! â€¢â€¢â€¢ ! :D :D :D !</s>\n",
            "1 <s> á‰¤áŒ£áˆ áŒ¥áˆ© áŠ“á‹á¢ áŠ á‰¥á‰¾á‹ áˆáŠ•á‹«á‹³áˆªáŒ‹áˆ áŠ áŠ•á‰° áŠ¨á‹áˆ²áŒ¥áŠ“ áŠ¨á‹áŒ« áŒ£áˆ‹á‰µ áŠ¥á‹°áˆ‹ áŠ¥á‹«á‹ˆáŠ­ áŠ¨á‹á‹²áˆáŠ­ áŒ‹áˆª áˆˆáˆáŠ• áŠ á‰µáˆ²áˆ›áˆ›áˆ?? á‹«áŠ• áŠ­á‰ á‹›áˆ›áŠ• áŠ á‰¥áˆ«á‰¹ áŠ áˆ³áˆá‹á‰¹á‹ á‹›áˆ¨áˆ›áˆ‹á‹«á‹«á‰³á‰¹ áŠ¥áŠ” á‰¤á‰£áŠ©áˆˆ á‰¤áŒ£áˆ áˆá‰¤áŠ• á‰†áˆ¶áˆá‹ˆáˆ áŠ á‰£áŠ¨á‰¹á‹ á‹¨áˆ³á‹ áˆ›áˆ³á‰‚á‹« áŠ á‰³á‹³áˆªáŒ‰áŠ• áŠ¡áŠ¡áˆáŠáŠ</s>\n",
            "1 <s> á‰³áŒáˆ¶ áˆˆáŠ–áˆ¨ áŒá‹œ áˆ˜áˆáˆµ áŠ áˆˆá‹á¢</s>\n",
            "0 <s> á‰ áŒ£áˆ áˆá‰¥ á‹¨áˆšáˆ°á‰¥áˆ­áŠ“ á‹¨áˆšá‹«áˆ³á‹áŠ•ğŸ˜­ áŠ¥áŒá‹šáŠ á‰¥áˆ”áˆ­ áŠááˆ³á‰¸á‹ á‹­áˆ›áˆ­: áˆˆá‰¤á‰°áˆ°á‰¦á‰¸á‹áŠ“ áˆˆá‹ˆá‹³áŒ†á‰»á‰¸á‹ áˆ˜á…áŠ“áŠ“á‰µáŠ•áŠ“ áŒ¥áŠ•áŠ«áˆ¬áŠ• á‹­áˆµáŒ£á‰¸á‹::</s>\n",
            "0 <s> á‰ á‹¨á‰€áŠ‘ áŠ¥áŠ® áŠ áˆ³á‹›áŠ á‹œáŠ“á‹á‰½áŠ• áŠ¥á‹¨áˆ°áˆ›áŠ• áŠá‹</s>\n",
            "0 <s> Happy 2020 á‰µáˆá‰… áˆ°á‹ :) áŠ‘áŠ‘áˆ» áˆá‰ áˆ‹á‰µ á‰‚á‰‚áˆ»...áŠ¥áŠ•á‹°á‹ á‹ˆáŠ”á‹‹ á‰°áˆ˜á‰½á‰¶áŠ áŠá‹ áŠ¥áŠ•áŒ‚:: á‰ áŒáˆšáŠ’áˆµá‰¶á‰¹ áŠ á‹²áˆµ á‹“áˆ˜á‰µ áˆáŒ‹ á‹¨áˆ†áŠá‰½ áŠ¨áˆœáŠ«á• áŠ¥áŠ“ áŠ¨á†á‰³á‹Š (áŠ¨áˆˆáˆªá‹áˆ:á‰¢á‹á‰²á‹áˆ:á‹ˆá‹˜á‰°) áŠ®á‰°á‰µ á‹¨áŒ¸á‹³á‰½ áŒ‰á‰¥áˆ á‹±á‰¥ á‹«á‹µáˆ­áŒáˆáˆ… áˆˆáˆ›áˆˆá‰µ áŠ¥á‹ˆá‹³áˆˆáˆğŸ˜Š</s>\n",
            "1 <s> áŠ¨áˆ…áŒáˆ… áˆ˜áˆáŠ«áˆ áŠáŒˆáˆ®á‰½áŠ• áŠ¥áŠ•á‹³á‹­ áŠ á‹­áŠ–á‰¼áŠ• áŠ­áˆá‰µğŸ™Œ</s>\n",
            "1 <s> áŠ¥áŠ”áˆ› áŠ¥áŠ® á‰ á‰ƒ áˆºá‰² á‹«á‹°áˆ¨áŒˆá‰½ áˆ´á‰µ á‹ˆá‹­áˆ áˆµáˆˆ á‹µáˆ¬/áˆ€áˆ¨áˆ­ á‹¨áˆ†áŠ áŠ áˆªá áŠáŒˆáˆ­ á‹¨áˆšáŠ“áŒˆáˆ­ áˆ³á‹­ áˆ°áˆáˆ¯áŠ•/áˆ°áˆáˆ©áŠ• áŠá‹ á‹¨áˆáŒ á‹­á‰€á‹</s>\n",
            "1 <s> áŠ áˆµá‰€á‹µáˆ˜á‹ á‹­áˆ„ áŠ¥áŠ•á‹°áˆšá‹«áˆ¸áŠ•á áŠáŒˆáˆ©áŠ•áŠ® áŠ áŠ•á‹³áŠ•á‹´ áŠ¥á‹áŠá‰µ á‰°áˆ«áˆ« áˆáŠ•á‰…áˆ á‹­á‹ˆáŒ£áˆ</s>\n",
            "1 <s> Every time áŠ•á‰¥ á‰¥áˆ­áŒ­á‰†á‹¬ áˆ‹á‹­ áˆáŠ“áˆáŠ• áˆ²á‹«áˆ­á áŠ¥áˆ›á‹¬ â€œáˆ²áˆ³á‹­ áŠá‹â€ á‹¨áˆá‰µáˆˆáŠ áŠáŒˆáˆ­ áŠ¥á‹áŠá‰µ á‰¢áˆ†áŠ• áŠ–áˆ® I would have been á‹¨áˆŒáˆˆ rich</s>\n",
            "1 <s> áŠ¥áŠ”áˆ áŠ¥áŠ“ á‰£áŠá‰ á‰¥áŠ©á‰µ á‰áŒ¥áˆ­ áˆ¸á‹‹áˆáˆ«á‹‰ (á‹¨á‹ˆáŠ•á‹¶á‰½ áŒ‰á‹³á‹­) á‰µá‹ á‹­áˆˆáŠáŠ“ áˆáŒˆáŒ á‹«á‹°áˆ­áŒˆáŠ›áˆá¢</s>\n",
            "1 <s> á‰³áŠ¨áˆˆ áŠ¡áˆ› á‹¨áŠ á‹²áˆµ áŠ á‰ á‰£ áˆ˜áˆ¬á‰µáŠ• á‰ áˆ«áˆ³á‰¸á‹ áá‰ƒá‹µ áŠ¨á‰¦á‰³á‹ áŠ¥á‹¨á‰°áŒˆáŠ™ á‹¨áŠ¥áŒ… áˆµáˆáŠ«á‰¸á‹áŠ• áˆˆá‰£áˆˆ áˆ€á‰¥á‰¶á‰½ á‰ áˆ˜áˆµáŒ á‰µ á‰½áŒáˆ­ áˆ²áˆáŒ áˆ­ áŠ¨áŒ¥á‰³ áˆˆáˆ³á‰¸á‹ á‰¥á‰» áŠ¥áŠ•á‹²á‹°á‹ˆáˆ á‰ áˆ›á‹µáˆ¨áŒ áŠ¥á‹¨áˆ°áˆ© áŠ¥áŠ•á‹°áˆ†áŠ á‰¥á‹™ áŠ áˆ³áˆ›áŠ áˆ˜áˆ¨áŒƒá‹á‰½ á‹­áˆ°áˆ›áˆ‰</s>\n",
            "1 <s> áŠ¨áˆŒá‰£ á‹˜áˆ«áŠ: áˆ°á‹¶áˆ›á‹Š: á‹˜áˆ¨áŠ› á‹ˆá‹«áŠ” áŒ‹áˆ­ áˆ˜áŠ–áˆ­ á‰€áˆ¨ á‰¢á‰£áˆ.... á€áˆá‹­ á‹ˆáŒ£áˆˆáŠ• áˆ›áˆˆá‰µ áŠá‹</s>\n",
            "0 <s> áˆµá‰¥áˆ°á‰£á‰½áŠ•áŠ• áŠ áŒ áŠ“á‰€áŠ“áˆ . á‹¨áŠ­áˆáˆ‹á‰½áŠ•áŠ• áŒ‰áˆµá‰áˆáŠ“ á‰ á‰€áŒ£á‹­áŠá‰µ á‹¨áˆšá‹«áˆ¨áŒ‹áŒáŒ¡ áŠ á‰…áŒ£áŒ«á‹á‰½áŠ• áŠ áˆµá‰€áˆáŒ áŠ“áˆ . áˆáŠ•áŒ­á¦ á‹¨áŒ‰áˆµá‰áˆáŠ“ á“áˆ­á‰²</s>\n",
            "1 <s> Anchi áŒ†áˆ­á‹³áŠ“ áŠ©áˆ½áŠ“ áŒ‹áˆ­ á‰°á‰€áŒ áˆ­áˆ½ áŠ¥áŠ•á‹´??? áˆáŒá‰¡ áŒáŠ• á‹«á‰ á‹° áŠá‹</s>\n",
            "0 <s> áŠ áˆ½áŠ¨áˆ­ áˆ°á‹ áˆ†áŠ– áŠ á‹«á‰…áˆá£ á‹ˆá‹­á‹˜áˆªá‰µ á‹°áŒáˆ áˆáˆ­áŒ¥ áŠ áˆ½áŠ¨áˆ­ áŠ¥áŠ“ áˆáˆ¨áˆµ áŠá‰½á¤</s>\n",
            "0 <s> : á‹­áŒˆáˆ­áˆ˜áŠ›áˆ :) áˆ«áˆ±áŠ• áˆ²á‹«á‰ áˆˆá…áŒ á‹¨áŠ¨áˆ¨áˆ˜ á‹¨áŠ¥áŠ•á‰¥áˆ‹á‹ áˆµá‰¥áˆµá‰¥ áˆµáˆ™áŠ• á‰€á‹­áˆ® áŠ á‹²áˆµ áˆ±á áˆˆá‰¥áˆ¶ á‰¥áˆá…áŒáŠ“ á‰¥áˆ áŠ¨á‰½ áŠ áŒˆáˆ¬ á‹­á‰…áŠ“áˆ½</s>\n",
            "1 <s> á‹¨á“áˆˆá‰²áŠ« prostitute áŠ¨áˆ˜áˆµáˆ«á‰µ áˆáˆ‰áŠ•áˆ á‰ áŠ¥áŠ©áˆ áŠ á‹­áŠ• áŠ¥á‹­á‰¶ á‰µáŠ­áŠ­áˆˆáŠ› áá‰µáˆ… áˆ˜á‹áˆ°á‹µ á‹­á‰½áˆ‹áˆ‰ áŠ•á‰¥áˆ¨á‰µ::</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDTkq3MlWN3q"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}