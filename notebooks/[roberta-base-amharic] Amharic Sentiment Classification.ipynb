{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Download Sentiment Dataset**"
      ],
      "metadata": {
        "id": "E_Guin6-ct-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -Uq datasets evaluate accelerate"
      ],
      "metadata": {
        "id": "s5LPXkHbhznR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip uninstall -y wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyFALq-LQfq8",
        "outputId": "934196bc-9b1b-44b4-8082-9c8bf76523ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping wandb as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "sentiment_dataset = load_dataset(\"rasyosef/amharic-sentiment\")\n",
        "sentiment_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoqmmemFydO1",
        "outputId": "c725727b-bb2a-47e0-c297-9a7140a2b853"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['clean_tweet', 'label'],\n",
              "        num_rows: 2223\n",
              "    })\n",
              "    dev: Dataset({\n",
              "        features: ['clean_tweet', 'label'],\n",
              "        num_rows: 279\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['clean_tweet', 'label'],\n",
              "        num_rows: 279\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_dataset[\"train\"].features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbCb0imbzrIF",
        "outputId": "28566024-123a-4c42-8ee9-8fdcf2ace3c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clean_tweet': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['negative', 'positive'], id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = sentiment_dataset[\"train\"].features[\"label\"].names\n",
        "label_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3deWqBSNzxsn",
        "outputId": "1ec590fb-d5ce-46fd-b5c6-7d687c04b991"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['negative', 'positive']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tokenize Tweets**"
      ],
      "metadata": {
        "id": "Cv2DfPGxmulq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_id = \"rasyosef/roberta-base-amharic\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "print(tokenizer.tokenize(\"ከሀገራቸው ከኢትዮጵያ ከወጡ ግማሽ ምዕተ <mask> ተቆጥሯል።\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg0Iq8gBm1e5",
        "outputId": "aeb4eafc-31fd-4c9c-b32c-9336a05f93f0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁ከ', 'ሀገራቸው', '▁ከኢትዮጵያ', '▁ከወጡ', '▁ግማሽ', '▁ምዕተ', ' <mask>', '▁ተቆጥ', 'ሯል።']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_dataset(samples):\n",
        "  tokenized_samples = tokenizer(samples[\"clean_tweet\"], truncation=True, max_length=512)\n",
        "  return tokenized_samples\n",
        "\n",
        "tokenize_dataset({\"clean_tweet\":[\"ከሀገራቸው ከኢትዮጵያ ከወጡ ግማሽ\"]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K4TDK_smYF9",
        "outputId": "abcaa385-bee6-42d5-9c12-912926f0c650"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[0, 17, 18090, 897, 13696, 2476, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_datasets = sentiment_dataset.map(\n",
        "    tokenize_dataset,\n",
        "    batched=True,\n",
        "    remove_columns=[\"clean_tweet\"]\n",
        "  )\n",
        "preprocessed_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW5DAkztoyzH",
        "outputId": "49c9999a-e3b5-47cb-cb74-0714ed07df81"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 2223\n",
              "    })\n",
              "    dev: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 279\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 279\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Amharic BERT model**"
      ],
      "metadata": {
        "id": "jP7R35bNq5-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id2label={i: label for i, label in enumerate(label_names)}\n",
        "label2id={label: i for i, label in enumerate(label_names)}\n",
        "\n",
        "print(id2label, label2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQCDsP_hsKgT",
        "outputId": "68a790db-c631-4297-929e-fa689fedc6ff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'negative', 1: 'positive'} {'negative': 0, 'positive': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=len(label_names),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    # device_map=\"cuda\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRIgwPh_pztu",
        "outputId": "ec6c10e2-bbe0-47b2-b23c-e133f421ca8d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at rasyosef/roberta-base-amharic and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Finetuning**"
      ],
      "metadata": {
        "id": "ncGTp5y2tCdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "q62avVBzsZ0d"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 3\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_id+\"-finetuned\",\n",
        "    learning_rate=4e-5,\n",
        "    #lr_scheduler_type=\"linear\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=epochs,\n",
        "    weight_decay=0.1,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    # load_best_model_at_end=True,\n",
        "    # metric_for_best_model=\"f1\",\n",
        "    fp16=True,\n",
        "    seed=16,\n",
        ")"
      ],
      "metadata": {
        "id": "fwru3t0bt_2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64d94657-f0ed-4eff-948b-57dc4e9d1857"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "  metric1 = evaluate.load(\"accuracy\")\n",
        "  metric2 = evaluate.load(\"precision\")\n",
        "  metric3 = evaluate.load(\"recall\")\n",
        "  metric4 = evaluate.load(\"f1\")\n",
        "\n",
        "  logits, labels = eval_preds\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "  accuracy = metric1.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "  # precision = metric2.compute(predictions=predictions, references=labels, average='macro')[\"precision\"]\n",
        "  # recall = metric3.compute(predictions=predictions, references=labels, average='macro')[\"recall\"]\n",
        "  # f1 = metric4.compute(predictions=predictions, references=labels, average='macro')[\"f1\"]\n",
        "\n",
        "  return {\n",
        "      \"accuracy\": accuracy,\n",
        "      # \"precision\": precision,\n",
        "      # \"recall\": recall,\n",
        "      # \"f1\": f1\n",
        "  }\n",
        "\n",
        "compute_metrics((np.array([[1,0], [0,1]]), np.array([0,1])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGU1-lE2vebs",
        "outputId": "1056140f-7c3b-4ff1-cceb-3ac7f9f07fe2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=preprocessed_datasets[\"train\"],\n",
        "    eval_dataset=preprocessed_datasets[\"dev\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "3SgipS5LxJtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d58ebf3-67b7-4eab-92d1-16041056afc5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-b0b54413edf8>:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "vQUu-msQ1_0I",
        "outputId": "b46b434c-d6ae-4dcf-b102-dcfae8aaeaef"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.6905758380889893,\n",
              " 'eval_model_preparation_time': 0.0318,\n",
              " 'eval_accuracy': 0.5232974910394266,\n",
              " 'eval_runtime': 6.5111,\n",
              " 'eval_samples_per_second': 42.85,\n",
              " 'eval_steps_per_second': 1.382}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "Rro_9eUF2CJA",
        "outputId": "543dc812-b871-4962-a378-125ec47cd2aa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [210/210 01:24, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Model Preparation Time</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.473200</td>\n",
              "      <td>0.348664</td>\n",
              "      <td>0.031800</td>\n",
              "      <td>0.870968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.256100</td>\n",
              "      <td>0.325395</td>\n",
              "      <td>0.031800</td>\n",
              "      <td>0.885305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.127800</td>\n",
              "      <td>0.407160</td>\n",
              "      <td>0.031800</td>\n",
              "      <td>0.878136</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=210, training_loss=0.28569967633201965, metrics={'train_runtime': 85.4741, 'train_samples_per_second': 78.024, 'train_steps_per_second': 2.457, 'total_flos': 233963797647180.0, 'train_loss': 0.28569967633201965, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "zY8apvbx76GW",
        "outputId": "f7e67082-e1ca-4205-ead9-d2826e305e02"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.40716004371643066,\n",
              " 'eval_model_preparation_time': 0.0318,\n",
              " 'eval_accuracy': 0.8781362007168458,\n",
              " 'eval_runtime': 2.2787,\n",
              " 'eval_samples_per_second': 122.436,\n",
              " 'eval_steps_per_second': 3.95,\n",
              " 'epoch': 3.0}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluate Model**"
      ],
      "metadata": {
        "id": "JIi7JNlx68TL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "num_samples = len(preprocessed_datasets[\"test\"])\n",
        "inputs = data_collator([preprocessed_datasets[\"test\"][i] for i in range(num_samples)])\n",
        "# print(inputs)\n",
        "\n",
        "y_pred = []\n",
        "\n",
        "#output = model(**inputs)\n",
        "for i in range(0, len(inputs[\"input_ids\"]), 8):\n",
        "  output = model(**{k: v[i:i+8].to(\"cuda\") for k, v in inputs.items()})\n",
        "  y_pred.extend(np.argmax(output.logits.tolist(), axis=-1))\n",
        "\n",
        "y_test = np.array(preprocessed_datasets[\"test\"][\"label\"])\n",
        "\n",
        "print(y_pred)\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIVaUrTm2MXD",
        "outputId": "f137aebd-f66d-4fae-9de4-1da5f909f7e5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]\n",
            "[1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1\n",
            " 0 1 1 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 0 0 1 0\n",
            " 0 1 0 1 1 0 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 1 1 1 1 0 1\n",
            " 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0\n",
            " 0 1 0 1 1 0 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0\n",
            " 1 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 1 1 1\n",
            " 0 0 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0\n",
            " 1 0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "metrics.confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "pb-tehHs71zg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "224cb20e-c09d-47a2-a1ab-fdea932f74e5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[131,  19],\n",
              "       [ 15, 114]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "t9zfLF5p8Sqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88238aaf-9d42-4e63-c194-b5a9be57ba59"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.87      0.89       150\n",
            "           1       0.86      0.88      0.87       129\n",
            "\n",
            "    accuracy                           0.88       279\n",
            "   macro avg       0.88      0.88      0.88       279\n",
            "weighted avg       0.88      0.88      0.88       279\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test in Pipeline**"
      ],
      "metadata": {
        "id": "zz1n-9P-sVls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
        "pipe(\"ቆንጆ ፊልም ነው\")"
      ],
      "metadata": {
        "id": "CeI9CeUwsamR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78c4cbef-f00f-4da6-a5b7-a344d665921a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'positive', 'score': 0.9946774244308472}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"አሪፍ ልብስ\")"
      ],
      "metadata": {
        "id": "10KPQ8e9s16w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d874a892-75de-4411-f236-aa801726b265"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'positive', 'score': 0.9932680726051331}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"ጅላንፎ\")"
      ],
      "metadata": {
        "id": "i84DslUCs-oY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceec115a-45af-46fc-9b94-388a7b30935d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'negative', 'score': 0.9898892045021057}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"እዚህ ሰፈር በማታ መጓዝ እፈራለሁ\")"
      ],
      "metadata": {
        "id": "ktEKYGhCtBLC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82886140-1129-4dd3-cb06-e0f10ddcd2c7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'negative', 'score': 0.9708817005157471}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"ዩክሬን እና ሩስያ ከባድ ውግያ ላይ ናቸው\")"
      ],
      "metadata": {
        "id": "SEThuPFCwOuz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6920b0-f3d6-4949-c95d-b6a5963b5662"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'negative', 'score': 0.9782395958900452}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mis-classified**"
      ],
      "metadata": {
        "id": "1IZvMcFjFvfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "misclassified = []\n",
        "for i in range(len(y_pred)):\n",
        "  if y_pred[i] != y_test[i]:\n",
        "    misclassified.append(i)\n",
        "\n",
        "print(misclassified)"
      ],
      "metadata": {
        "id": "e0YF7s0p2YdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "552605db-af6b-4c64-abd9-a8e20561bff7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 8, 12, 13, 23, 29, 33, 49, 53, 59, 65, 81, 89, 93, 99, 100, 103, 107, 115, 120, 125, 137, 147, 154, 173, 201, 203, 211, 220, 239, 240, 243, 249, 268]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in misclassified:\n",
        "  input_ids = preprocessed_datasets[\"test\"][idx][\"input_ids\"]\n",
        "  label = preprocessed_datasets[\"test\"][idx][\"label\"]\n",
        "  print(label, tokenizer.decode(input_ids))"
      ],
      "metadata": {
        "id": "0JvMqYDOFzti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc66797d-98d9-4f1d-b85b-e2693729b14d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 <s> የሸገር ልዩ ወሬ-በጦርነት እና በሕመም 5 ልጆቻቸውን ያጡት የጨው በረንዳዋ እማሆይ ፀሐይነሽ ኃይሉ ዓይኖቻቸውን ያጡት በእንባ ብዛት ነው</s>\n",
            "0 <s> እንደሱማ ከሆነ እናንተም ቦታ ላይኖራችሁ ነው</s>\n",
            "1 <s> እንዲህ አይነት ርዕስ ጽፎ ለበዐል ይጠብቁን ድንግርግር ይላል ግን አሻም በበዓልም አልቀልድም ካለ ምን ይደረግ? 😃 ስሜነህ አያሌውና ሱራፌል ሲጠይቁ እንኳን ብንሰማ ይሻለናል በውነት።</s>\n",
            "0 <s> ከእንደ አንተ አይነቱ ደደብ መሀይም ጭራቅ የምንላቀቅበት ዘመን ይሁን!!! ሁሌም አብየየየየ</s>\n",
            "0 <s> ሰሊ እውነት አንቺ አማኝ ነሽ ከዚህ ሂጂ😄</s>\n",
            "0 <s> ያሰብከው ሁሉ ይሳካ! በእውነትና እውቀትና በተመሰረትርው ራዕይ ፓርቲ ኢትዮጵያና ህዝቦችዋ ታፍረውና ተከውረው ይኖራሉ።</s>\n",
            "0 <s> አጋንንቶች ነፍሴን ይመገባሉ። መሪዬን አገለግላለሁ ፡፡ እኔ ነፍሳትን አመጣለሁ</s>\n",
            "0 <s> በመካከላችን ማንም የለም ፣ በገዛ እጄ ከገደለው ፍጥረት ሁሉ ጋር እኖራለሁ ምንም እንኳን ከእንግዲህ ከእኛ ጋር ባይሆንም</s>\n",
            "0 <s> ታሪካችን ፡ እንደገና ፡ ተበዉዞ ፡ መስራት ፡ አለበት ፡ እስካሁን ፡ ያለው ፡ የኣንድ ፡ ወገን ፡ ታሪክ ፡ ነው።</s>\n",
            "0 <s> ከሀገሬው ይልቅ ለቻይናዉያን ምቹ የሆነች ሀገር <unk>...</s>\n",
            "1 <s> ኦሮምያ የደጋገዎች አገር ናት እንጂ አጋች ታጋች ዲራማ የሚካሄድ በት ክልል አይደለም</s>\n",
            "1 <s> ለመልካም ዕድልሲል በአውሮፕላን ሞተር ውስጥ ሳንቲም የወረወረው ግለሰብ ተቀጣ! ሉ የተሳፋሪውን እንቅስቃሴን በማወክ በሚል በፖሊስ ለ10ቀናት በእስር ቆይቶ ጉዳዩ በሲቪል ኬስ ታይቶ ካሳ 17,600 ዶላር ኪሳራ እንዲከፍል አስረድቷል!</s>\n",
            "1 <s> ፅንፈኛ ፋኖ የሚባል የለም <unk>🏾 <unk>️እዛው ወደዚያ ጉዳቹሁ እየወጣ ነው ምድረ ሰው በላ አውሬዎች መስጊድ አቃጥላቹ አማራውን ለማባላት ለዛሬ አልተሳካም ጥፉ ከዚህ መርዝ</s>\n",
            "0 <s> ልብ ወለድ መጽሃፍ እኮ እላልኩም:: ትክክለኛ ማስረጃ ነው ያልኩት!</s>\n",
            "1 <s> 2)ለሕገወጥም መንገድ በር እየከፈተ ነው የግባታ ፈቃድ ለድርጅት ለንግድ ተቋማት አሥፈላጊ ነው ግንባታው በአጭር ጊዜባለመጠናቀቁ ሐገር ከሚያመነጨው ኢኮኖሚ ታጣለች መኖሪያ ቤት ተሎ ባለመሥራቱ በኪራይ ደረጃ ባልጠበቀ አለመኖሩ ግለሠቡን ነው የሚጎዳ</s>\n",
            "0 <s> አሜን ኣሜን ኣሜን ።</s>\n",
            "0 <s> : ከፖለቲከኞች የምንጠብቀውን ዘላቂ ታማኝነት አንዳንዱ ሕልም ብቻ ሲያደርግብን ለጋራ አላማ ከፍተኛ የግል መስዋዕትነት እየከፈሉ ያሉ መኖራቸውም ግልፅ እየሆነ ነው:: እኛ ል...</s>\n",
            "1 <s> ትግራይና ህወሓት ለያይቶ ማየቱ ይሻላል፡ ደሞ ይሄንን ጉዳይ ክልሉን ለማጥቃት ነው። መስማማት እንዳለ ሆኖ አለመስማማት should be acceptable. ሌላው ቀጣዩ ምርጫ ሚፈታው ጉዳይ ነው፡ ክልሉን ለመጉዳትና ህዝቡን ለማሳቀቅ የሚደረግ ስራ ግን መቆም አለበት</s>\n",
            "1 <s> \"አልገልህምን ምን አመጣው\" ይላል ያገሬ ሰው</s>\n",
            "0 <s> ለእነሱ ምርጥ የክርክር መልስ አለኝ - \"ፋኩ!\" :-)</s>\n",
            "0 <s> \"ካቀድነው በላይ ታጋች ያሥፈታን ቢሆንም ከእቅዳችን ጋ ይሠናሠል ዘንድ አንዳንዶቹን መልሠን ለአጋቾቹ ሠጥተናል!\" ወይዘሮ ንጉሡ ጥላሁን! ••• ! :D :D :D !</s>\n",
            "1 <s> ባለፈው ደማቅዋ ባህርዳር ቀጣይነች እንዳልነው፣ ተራዋ ደርዎ በባለኮኮቡ ሰደቅ በውበት ላይ ወበት ጨምራለች.... የጣና ዳር !</s>\n",
            "0 <s> በጣም ልብ የሚሰብርና የሚያሳዝን😭 እግዚአብሔር ነፍሳቸው ይማር: ለቤተሰቦቸውና ለወዳጆቻቸው መፅናናትንና ጥንካሬን ይስጣቸው::</s>\n",
            "0 <s> የገንዲ መድሐኒት እንደ ተወጋ በሬ ፈዘናል።ተስፋችንን ለኢዜማ አስረክበን ከህወሓት የባሰውን ዘመን በቁዘማ እየጠበቅን ነው</s>\n",
            "0 <s> Happy 2020 ትልቅ ሰው :) ኑኑሻ ልበላት ቂቂሻ...እንደው ወኔዋ ተመችቶኝ ነው እንጂ:: በፌሚኒስቶቹ አዲስ ዓመት ሎጋ የሆነች ከሜካፕ እና ከፆታዊ (ከለሪዝም:ቢውቲዝም:ወዘተ) ኮተት የጸዳች ጉብል ዱብ ያድርግልህ ለማለት እወዳለሁ😊</s>\n",
            "1 <s> \"እንኳን ጭንቅላትህ ተረፈ\" ነው ያልከው ደሞ \"እንኳን ማርያም ማራችሁ\" አይደለም</s>\n",
            "1 <s> እኔማ እኮ በቃ ሺቲ ያደረገች ሴት ወይም ስለ ድሬ/ሀረር የሆነ አሪፍ ነገር የሚናገር ሳይ ሰፈሯን/ሰፈሩን ነው የምጠይቀው</s>\n",
            "1 <s> Every time ንብ ብርጭቆዬ ላይ ምናምን ሲያርፍ እማዬ “ሲሳይ ነው” የምትለኝ ነገር እውነት ቢሆን ኖሮ I would have been የሌለ rich</s>\n",
            "1 <s> ታከለ ኡማ የአዲስ አበባ መሬትን በራሳቸው ፍቃድ ከቦታው እየተገኙ የእጅ ስልካቸውን ለባለ ሀብቶች በመስጠት ችግር ሲፈጠር ከጥታ ለሳቸው ብቻ እንዲደወል በማድረግ እየሰሩ እንደሆነ ብዙ አሳማኝ መረጃዎች ይሰማሉ</s>\n",
            "1 <s> ከሌባ ዘራፊ: ሰዶማዊ: ዘረኛ ወያኔ ጋር መኖር ቀረ ቢባል.... ፀሐይ ወጣለን ማለት ነው</s>\n",
            "1 <s> ባለፉት አምስት አመታት አካባቢ የአማራ ክልልን ሙዚየም ያሰራው የባህልና ቱ ቢሮ እስከአሁን ጥሩ ሄዶበታል። ነገር ግን ከእዚህ በኋላ መሬት ሊነካ ግድ ይለዋል።</s>\n",
            "0 <s> ስብሰባችንን አጠናቀናል . የክልላችንን ጉስቁልና በቀጣይነት የሚያረጋግጡ አቅጣጫዎችን አስቀምጠናል . ምንጭ፦ የጉስቁልና ፓርቲ</s>\n",
            "1 <s> Anchi ጆርዳና ኩሽና ጋር ተቀጠርሽ እንዴ??? ምግቡ ግን ያበደ ነው</s>\n",
            "0 <s> ODP የብልፅግና ፓርቲ አፋን ኦሮሞ አስተርጓሚ ነው !</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDTkq3MlWN3q"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}