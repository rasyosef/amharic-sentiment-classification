{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Download Sentiment Dataset**"
      ],
      "metadata": {
        "id": "E_Guin6-ct-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -Uq datasets evaluate accelerate"
      ],
      "metadata": {
        "id": "s5LPXkHbhznR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip uninstall -y wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyFALq-LQfq8",
        "outputId": "0bcd62b4-5aa0-47cf-f699-f4cec4f9edc5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping wandb as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "sentiment_dataset = load_dataset(\"rasyosef/amharic-sentiment\")\n",
        "sentiment_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoqmmemFydO1",
        "outputId": "92eb2fea-3aaa-4f5b-d48c-f191c99f62f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['clean_tweet', 'label'],\n",
              "        num_rows: 2223\n",
              "    })\n",
              "    dev: Dataset({\n",
              "        features: ['clean_tweet', 'label'],\n",
              "        num_rows: 279\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['clean_tweet', 'label'],\n",
              "        num_rows: 279\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_dataset[\"train\"].features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbCb0imbzrIF",
        "outputId": "cd8c06ef-f7ce-4bbf-b542-f0e2f3d935da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clean_tweet': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['negative', 'positive'], id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = sentiment_dataset[\"train\"].features[\"label\"].names\n",
        "label_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3deWqBSNzxsn",
        "outputId": "71738849-4c7e-44a9-a3bd-975300cae91d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['negative', 'positive']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tokenize Tweets**"
      ],
      "metadata": {
        "id": "Cv2DfPGxmulq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_id = \"Davlan/afro-xlmr-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "print(tokenizer.tokenize(\"ከሀገራቸው ከኢትዮጵያ ከወጡ ግማሽ ምዕተ <mask> ተቆጥሯል።\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg0Iq8gBm1e5",
        "outputId": "ab587928-34dc-4433-af9a-f13e54d1f6f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁ከ', 'ሀ', 'ገ', 'ራቸው', '▁ከኢትዮጵያ', '▁ከ', 'ወጡ', '▁', 'ግማሽ', '▁', 'ምዕ', 'ተ', ' <mask>', '▁ተ', 'ቆ', 'ጥ', 'ሯል።']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_dataset(samples):\n",
        "  tokenized_samples = tokenizer(samples[\"clean_tweet\"], truncation=True, max_length=512)\n",
        "  return tokenized_samples\n",
        "\n",
        "tokenize_dataset({\"clean_tweet\":[\"ከሀገራቸው ከኢትዮጵያ ከወጡ ግማሽ\"]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K4TDK_smYF9",
        "outputId": "2ab5afe6-9e63-42c2-9cdb-62b6af291201"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[0, 1464, 21608, 5430, 66052, 165627, 1464, 87365, 6, 230446, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_datasets = sentiment_dataset.map(\n",
        "    tokenize_dataset,\n",
        "    batched=True,\n",
        "    remove_columns=[\"clean_tweet\"]\n",
        "  )\n",
        "preprocessed_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW5DAkztoyzH",
        "outputId": "86256253-7d5c-4466-d14d-2742b165b062"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 2223\n",
              "    })\n",
              "    dev: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 279\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 279\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Amharic BERT model**"
      ],
      "metadata": {
        "id": "jP7R35bNq5-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id2label={i: label for i, label in enumerate(label_names)}\n",
        "label2id={label: i for i, label in enumerate(label_names)}\n",
        "\n",
        "print(id2label, label2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQCDsP_hsKgT",
        "outputId": "0aaef8a8-5062-485e-ebb6-0e8e8c54aee0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'negative', 1: 'positive'} {'negative': 0, 'positive': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=len(label_names),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    # device_map=\"cuda\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRIgwPh_pztu",
        "outputId": "adff7821-1b6c-4153-8aa8-3dd2543d1581"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Finetuning**"
      ],
      "metadata": {
        "id": "ncGTp5y2tCdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "q62avVBzsZ0d"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 3\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_id+\"-finetuned\",\n",
        "    learning_rate=2e-5,\n",
        "    # lr_scheduler_type=\"linear\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=epochs,\n",
        "    weight_decay=0.1,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    # load_best_model_at_end=True,\n",
        "    # metric_for_best_model=\"f1\",\n",
        "    fp16=True,\n",
        "    seed=16,\n",
        ")"
      ],
      "metadata": {
        "id": "fwru3t0bt_2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1bed98c-765b-4ba3-b84c-84ecb874f318"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "  metric1 = evaluate.load(\"accuracy\")\n",
        "  metric2 = evaluate.load(\"precision\")\n",
        "  metric3 = evaluate.load(\"recall\")\n",
        "  metric4 = evaluate.load(\"f1\")\n",
        "\n",
        "  logits, labels = eval_preds\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "  accuracy = metric1.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "  # precision = metric2.compute(predictions=predictions, references=labels, average='macro')[\"precision\"]\n",
        "  # recall = metric3.compute(predictions=predictions, references=labels, average='macro')[\"recall\"]\n",
        "  # f1 = metric4.compute(predictions=predictions, references=labels, average='macro')[\"f1\"]\n",
        "\n",
        "  return {\n",
        "      \"accuracy\": accuracy,\n",
        "      # \"precision\": precision,\n",
        "      # \"recall\": recall,\n",
        "      # \"f1\": f1\n",
        "  }\n",
        "\n",
        "compute_metrics((np.array([[1,0], [0,1]]), np.array([0,1])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGU1-lE2vebs",
        "outputId": "25aa0feb-c23a-4405-8666-0ae27f51c642"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=preprocessed_datasets[\"train\"],\n",
        "    eval_dataset=preprocessed_datasets[\"dev\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "3SgipS5LxJtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94998e1c-0a60-429d-aca5-a026be8bc3ec"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-b0b54413edf8>:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "vQUu-msQ1_0I",
        "outputId": "8efbfbf2-fcd7-4360-ff4a-1c347256ed88"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.6882262825965881,\n",
              " 'eval_model_preparation_time': 0.0038,\n",
              " 'eval_accuracy': 0.5340501792114696,\n",
              " 'eval_runtime': 6.1755,\n",
              " 'eval_samples_per_second': 45.179,\n",
              " 'eval_steps_per_second': 1.457}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "Rro_9eUF2CJA",
        "outputId": "de0e0715-9ea5-4ea0-a03c-1bcf8caaa630"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [210/210 03:14, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Model Preparation Time</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.551100</td>\n",
              "      <td>0.353497</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>0.878136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.387300</td>\n",
              "      <td>0.361035</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>0.860215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.331900</td>\n",
              "      <td>0.364352</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>0.856631</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:22]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=210, training_loss=0.4234596161615281, metrics={'train_runtime': 195.4515, 'train_samples_per_second': 34.121, 'train_steps_per_second': 1.074, 'total_flos': 289544980314420.0, 'train_loss': 0.4234596161615281, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "zY8apvbx76GW",
        "outputId": "e52265b0-11d3-4d29-a75f-ab3e44102086"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.3643520474433899,\n",
              " 'eval_model_preparation_time': 0.0038,\n",
              " 'eval_accuracy': 0.8566308243727598,\n",
              " 'eval_runtime': 5.1705,\n",
              " 'eval_samples_per_second': 53.96,\n",
              " 'eval_steps_per_second': 1.741,\n",
              " 'epoch': 3.0}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluate Model**"
      ],
      "metadata": {
        "id": "JIi7JNlx68TL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "num_samples = len(preprocessed_datasets[\"test\"])\n",
        "inputs = data_collator([preprocessed_datasets[\"test\"][i] for i in range(num_samples)])\n",
        "# print(inputs)\n",
        "\n",
        "y_pred = []\n",
        "\n",
        "#output = model(**inputs)\n",
        "for i in range(0, len(inputs[\"input_ids\"]), 5):\n",
        "  output = model(**{k: v[i:i+5].to(\"cuda\") for k, v in inputs.items()})\n",
        "  y_pred.extend(np.argmax(output.logits.tolist(), axis=-1))\n",
        "\n",
        "y_test = np.array(preprocessed_datasets[\"test\"][\"label\"])\n",
        "\n",
        "print(y_pred)\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIVaUrTm2MXD",
        "outputId": "d7f3d9c1-648f-4959-fd5d-8018830d4a1b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
            "[1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1\n",
            " 0 1 1 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 0 0 1 0\n",
            " 0 1 0 1 1 0 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 1 1 1 1 0 1\n",
            " 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0\n",
            " 0 1 0 1 1 0 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0\n",
            " 1 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 1 1 1\n",
            " 0 0 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0\n",
            " 1 0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "metrics.confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "pb-tehHs71zg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3abc4af-9be2-40fb-deed-6408636ba31f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[126,  24],\n",
              "       [ 24, 105]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "t9zfLF5p8Sqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f24673-7e14-4b50-b4b2-2d517392d4ec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84       150\n",
            "           1       0.81      0.81      0.81       129\n",
            "\n",
            "    accuracy                           0.83       279\n",
            "   macro avg       0.83      0.83      0.83       279\n",
            "weighted avg       0.83      0.83      0.83       279\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test in Pipeline**"
      ],
      "metadata": {
        "id": "zz1n-9P-sVls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
        "pipe(\"ቆንጆ ፊልም ነው\")"
      ],
      "metadata": {
        "id": "CeI9CeUwsamR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "346fe40e-61c7-48e5-c9e0-007b180791f5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'positive', 'score': 0.9071478247642517}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"አሪፍ ልብስ\")"
      ],
      "metadata": {
        "id": "10KPQ8e9s16w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eeb9c87-115e-4590-ace0-8a702b830631"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'positive', 'score': 0.8300437331199646}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"ጅላንፎ\")"
      ],
      "metadata": {
        "id": "i84DslUCs-oY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd8e5408-0b0c-466d-dc7e-7986478b29c4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'negative', 'score': 0.889720618724823}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"እዚህ ሰፈር በማታ መጓዝ እፈራለሁ\")"
      ],
      "metadata": {
        "id": "ktEKYGhCtBLC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b777325d-8c76-4268-a754-3eebf7613328"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'positive', 'score': 0.7218903303146362}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"ዩክሬን እና ሩስያ ከባድ ውግያ ላይ ናቸው\")"
      ],
      "metadata": {
        "id": "SEThuPFCwOuz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7be6829-1310-4c68-de1d-4017fd6e3e88"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'negative', 'score': 0.6785932183265686}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mis-classified**"
      ],
      "metadata": {
        "id": "1IZvMcFjFvfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "misclassified = []\n",
        "for i in range(len(y_pred)):\n",
        "  if y_pred[i] != y_test[i]:\n",
        "    misclassified.append(i)\n",
        "\n",
        "print(misclassified)"
      ],
      "metadata": {
        "id": "e0YF7s0p2YdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af457c63-4b0b-4de8-e96b-aa553d30bc9c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8, 12, 13, 24, 29, 33, 35, 36, 49, 53, 54, 59, 63, 65, 67, 72, 74, 81, 89, 93, 99, 100, 102, 103, 107, 115, 120, 125, 137, 144, 147, 164, 173, 186, 197, 201, 211, 212, 219, 220, 239, 243, 249, 250, 253, 254, 258, 270]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in misclassified:\n",
        "  input_ids = preprocessed_datasets[\"test\"][idx][\"input_ids\"]\n",
        "  label = preprocessed_datasets[\"test\"][idx][\"label\"]\n",
        "  print(label, tokenizer.decode(input_ids))"
      ],
      "metadata": {
        "id": "0JvMqYDOFzti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86902d3-9641-4ba8-c8eb-cc950fc249cf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 <s> እንደሱማ ከሆነ እናንተም ቦታ ላይኖራችሁ ነው</s>\n",
            "1 <s> እንዲህ አይነት ርዕስ ጽፎ ለበዐል ይጠብቁን ድንግርግር ይላል ግን አሻም በበዓልም አልቀልድም ካለ ምን ይደረግ? 😃 ስሜነህ አያሌውና ሱራፌል ሲጠይቁ እንኳን ብንሰማ ይሻለናል በውነት።</s>\n",
            "0 <s> ከእንደ አንተ አይነቱ ደደብ መሀይም ጭራቅ የምንላቀቅበት ዘመን ይሁን!!! ሁሌም አብየየየየ</s>\n",
            "1 <s> ዛሬ እንደ እኔ ምህረት የበዛለት ማን ነው???</s>\n",
            "0 <s> ያሰብከው ሁሉ ይሳካ! በእውነትና እውቀትና በተመሰረትርው ራዕይ ፓርቲ ኢትዮጵያና ህዝቦችዋ ታፍረውና ተከውረው ይኖራሉ።</s>\n",
            "0 <s> አጋንንቶች ነፍሴን ይመገባሉ። መሪዬን አገለግላለሁ ፡፡ እኔ ነፍሳትን አመጣለሁ</s>\n",
            "0 <s> ይገርማል እኔም ለአንድ ወገን እየሰራ እንዳለ ስነግረው ወዲያው ብሎክ አደረገኝ</s>\n",
            "1 <s> እንዲህ አይነቱን የተባረከና የተቀደሰውን ተግባር እየሰራህ በሸርና በተንኮል ላይ የተሰማሩትን አንጀታቸውን አድብናቸው:: መቼም ይህን ባዩ ግዜ ደም እንባ እንደሚያነቡ እርግጠኛ ነኝ:: የእነዚያ አምላክ ይጠብቅህ🙏🏿</s>\n",
            "0 <s> በመካከላችን ማንም የለም ፣ በገዛ እጄ ከገደለው ፍጥረት ሁሉ ጋር እኖራለሁ ምንም እንኳን ከእንግዲህ ከእኛ ጋር ባይሆንም</s>\n",
            "0 <s> ታሪካችን ፡ እንደገና ፡ ተበዉዞ ፡ መስራት ፡ አለበት ፡ እስካሁን ፡ ያለው ፡ የኣንድ ፡ ወገን ፡ ታሪክ ፡ ነው።</s>\n",
            "0 <s> : በተስፋ የምትጠብቅ እናት በሠላም የላከችው ልጇ ሬሳው በሳጥን ተጭኖ ሲመጣላት የሚሰማትን የሀዘን ስሜት ከባድ ነው ስለዚህ እማራለሁ ብለሁ ብለው ሄደው እሬሳቸው ለቤተ...</s>\n",
            "0 <s> ከሀገሬው ይልቅ ለቻይናዉያን ምቹ የሆነች ሀገር 🙃...</s>\n",
            "0 <s> ተዋ😄 እኔ ለሃገሪቷ ስለትምህት ፣ ሰላም፣ ጤና ፣ መሰረተ ልማት ፣ ውጭ ጉዳይ ወዘተ... ይሄን ፖሊሲ ይዤ መጥቻለሁ የሚል የፓርቲዎች ወግ ነው የናፈቀኝ። ቢያንስ እንደማህበረሰብ የፖለቲካ ንቃታችንን ይጨምርልናል። ባንስማማም ውይይት መልመድ አለብን።</s>\n",
            "1 <s> ኦሮምያ የደጋገዎች አገር ናት እንጂ አጋች ታጋች ዲራማ የሚካሄድ በት ክልል አይደለም</s>\n",
            "1 <s> 🤣🤣🤣🤣 እሺ ፌሪዬ ሾሚ ለመቀጣት ዝግጁ ነኝ</s>\n",
            "1 <s> : ጉድለትን ቢያወሩት፣ ለምን ይሄ አልሆነም እያሉ ቢጠይቁ ማለቂያም መልስም አይገኝም። 'እኔ ምን ላድርግ' ብሎ መነሳትን የመሰለ የእርካታ ምንጭ ግን ፍጹም የለም። በርታ ወዳጄ። 'ተሳካ'፣ 'አለቀ'...</s>\n",
            "0 <s> ታዋቂዋ የአል-ሃዳዝ እና የአል-አረቢያ ቴሌቪዥን የዜና ፕሮግራም አቅራቢ ናጅዋ ካሴም በ52 አመቷ ዛሬ ጠዋት ከዚህ አለም በሞት ተለየች፡፡</s>\n",
            "1 <s> ለመልካም ዕድልሲል በአውሮፕላን ሞተር ውስጥ ሳንቲም የወረወረው ግለሰብ ተቀጣ! ሉ የተሳፋሪውን እንቅስቃሴን በማወክ በሚል በፖሊስ ለ10ቀናት በእስር ቆይቶ ጉዳዩ በሲቪል ኬስ ታይቶ ካሳ 17,600 ዶላር ኪሳራ እንዲከፍል አስረድቷል!</s>\n",
            "1 <s> ፅንፈኛ ፋኖ የሚባል የለም 🤷🏾 ♀️እዛው ወደዚያ ጉዳቹሁ እየወጣ ነው ምድረ ሰው በላ አውሬዎች መስጊድ አቃጥላቹ አማራውን ለማባላት ለዛሬ አልተሳካም ጥፉ ከዚህ መርዝ</s>\n",
            "0 <s> ልብ ወለድ መጽሃፍ እኮ እላልኩም:: ትክክለኛ ማስረጃ ነው ያልኩት!</s>\n",
            "1 <s> 2)ለሕገወጥም መንገድ በር እየከፈተ ነው የግባታ ፈቃድ ለድርጅት ለንግድ ተቋማት አሥፈላጊ ነው ግንባታው በአጭር ጊዜባለመጠናቀቁ ሐገር ከሚያመነጨው ኢኮኖሚ ታጣለች መኖሪያ ቤት ተሎ ባለመሥራቱ በኪራይ ደረጃ ባልጠበቀ አለመኖሩ ግለሠቡን ነው የሚጎዳ</s>\n",
            "0 <s> አሜን ኣሜን ኣሜን ።</s>\n",
            "0 <s> : በአዲስ አበባ ከተማ በዓመት በአማካይ ከ20 በላይ ሰዎች በእብድ ውሻ በሽታ ህይወታቸውን እንደሚያጡ የኢትዮጵያ ሕብረተሰብ ጤና ኢንስቲትዩት አስታወቀ፡፡ በተጨማሪም በዓመት በአማካይ 10 ሺ 800 ሰዎ...</s>\n",
            "0 <s> : ከፖለቲከኞች የምንጠብቀውን ዘላቂ ታማኝነት አንዳንዱ ሕልም ብቻ ሲያደርግብን ለጋራ አላማ ከፍተኛ የግል መስዋዕትነት እየከፈሉ ያሉ መኖራቸውም ግልፅ እየሆነ ነው:: እኛ ል...</s>\n",
            "1 <s> ትግራይና ህወሓት ለያይቶ ማየቱ ይሻላል፡ ደሞ ይሄንን ጉዳይ ክልሉን ለማጥቃት ነው። መስማማት እንዳለ ሆኖ አለመስማማት should be acceptable. ሌላው ቀጣዩ ምርጫ ሚፈታው ጉዳይ ነው፡ ክልሉን ለመጉዳትና ህዝቡን ለማሳቀቅ የሚደረግ ስራ ግን መቆም አለበት</s>\n",
            "1 <s> \"አልገልህምን ምን አመጣው\" ይላል ያገሬ ሰው</s>\n",
            "0 <s> ለእነሱ ምርጥ የክርክር መልስ አለኝ - \"ፋኩ!\" :-)</s>\n",
            "0 <s> \"ካቀድነው በላይ ታጋች ያሥፈታን ቢሆንም ከእቅዳችን ጋ ይሠናሠል ዘንድ አንዳንዶቹን መልሠን ለአጋቾቹ ሠጥተናል!\" ወይዘሮ ንጉሡ ጥላሁን! ••• ! :D :D :D !</s>\n",
            "1 <s> ባለፈው ደማቅዋ ባህርዳር ቀጣይነች እንዳልነው፣ ተራዋ ደርዎ በባለኮኮቡ ሰደቅ በውበት ላይ ወበት ጨምራለች.... የጣና ዳር !</s>\n",
            "1 <s> ቤጣም ጥሩ ናው። አብቾው ምንያዳሪጋል አንተ ከውሲጥና ከውጫ ጣላት እደላ እያወክ ከውዲምክ ጋሪ ለምን አትሲማማም?? ያን ክፉ ዛማን አብራቹ አሳልፋቹው ዛረማላያያታቹ እኔ ቤባኩለ ቤጣም ልቤን ቆሶሎወል አባከቹው የሳው ማሳቂያ አታዳሪጉን ኡኡፈፊፊ</s>\n",
            "0 <s> በጣም ልብ የሚሰብርና የሚያሳዝን😭 እግዚአብሔር ነፍሳቸው ይማር: ለቤተሰቦቸውና ለወዳጆቻቸው መፅናናትንና ጥንካሬን ይስጣቸው::</s>\n",
            "0 <s> ልክ ነሽ! ከአይኑ በስተጀርባ ነገር ያዘለ ይመስላል::</s>\n",
            "0 <s> Happy 2020 ትልቅ ሰው :) ኑኑሻ ልበላት ቂቂሻ...እንደው ወኔዋ ተመችቶኝ ነው እንጂ:: በፌሚኒስቶቹ አዲስ ዓመት ሎጋ የሆነች ከሜካፕ እና ከፆታዊ (ከለሪዝም:ቢውቲዝም:ወዘተ) ኮተት የጸዳች ጉብል ዱብ ያድርግልህ ለማለት እወዳለሁ😊</s>\n",
            "1 <s> አንተን አምኖ ያፈረ የለምና!!! የኔ ድርሳን አድግ በይልኝ</s>\n",
            "1 <s> እውነት ነው .... ግን ምን አለበት እውነተኛ ለሆነው እስክንድር ነጋ : ለእውነት የቆመውን እስክንድር ነጋን አንተም ነፃነቱን ሰጥትህ እሱን እንደመከርከው አንተም ደሞ የማያዳላ መሪ ለሁሉም የቆምክ: ሁሉንም እኩል የምታስተዳድር መሪ ብትሆን!</s>\n",
            "1 <s> \"እንኳን ጭንቅላትህ ተረፈ\" ነው ያልከው ደሞ \"እንኳን ማርያም ማራችሁ\" አይደለም</s>\n",
            "1 <s> Every time ንብ ብርጭቆዬ ላይ ምናምን ሲያርፍ እማዬ “ሲሳይ ነው” የምትለኝ ነገር እውነት ቢሆን ኖሮ I would have been የሌለ rich</s>\n",
            "1 <s> በስህተት ወደ አካውንታቸው የገባውን አንድ ሚልዮን ብር በቅንነት የመለሱት ግለሰብ- አቶ ደሳለኝ ብስራት! \"ቅንነት እውነትን ለራስ መንገር ሲሆን ታማኝነት ደግሞ ሀቁን ለሌሎች መንገር ነው\"--- ስፔንሰር ጆንሰን Via Lion International Bank S.C.</s>\n",
            "1 <s> እኔም እና ባነበብኩት ቁጥር ሸዋፈራዉ (የወንዶች ጉዳይ) ትዝ ይለኝና ፈገግ ያደርገኛል።</s>\n",
            "1 <s> ታከለ ኡማ የአዲስ አበባ መሬትን በራሳቸው ፍቃድ ከቦታው እየተገኙ የእጅ ስልካቸውን ለባለ ሀብቶች በመስጠት ችግር ሲፈጠር ከጥታ ለሳቸው ብቻ እንዲደወል በማድረግ እየሰሩ እንደሆነ ብዙ አሳማኝ መረጃዎች ይሰማሉ</s>\n",
            "1 <s> ከሌባ ዘራፊ: ሰዶማዊ: ዘረኛ ወያኔ ጋር መኖር ቀረ ቢባል.... ፀሐይ ወጣለን ማለት ነው</s>\n",
            "0 <s> ስብሰባችንን አጠናቀናል . የክልላችንን ጉስቁልና በቀጣይነት የሚያረጋግጡ አቅጣጫዎችን አስቀምጠናል . ምንጭ፦ የጉስቁልና ፓርቲ</s>\n",
            "1 <s> Anchi ጆርዳና ኩሽና ጋር ተቀጠርሽ እንዴ??? ምግቡ ግን ያበደ ነው</s>\n",
            "0 <s> አሽከር ሰው ሆኖ አያቅም፣ ወይዘሪት ደግሞ ምርጥ አሽከር እና ፈረስ ነች፤</s>\n",
            "0 <s> JUST_FOR_FUN አንዱ ጀለስ በጣም ስልቹ ከመሆኑ የተነሳ አንድ ቀን ሚስቱ በር አንኳኩታ ተነስቶ መክፈት ደብሮት ምን ቢል ጥሩ ነው . . . . . . . . በቃ ፈትቼሻለሁ በዛው ሂጂ😏😂😂 Fankim Islamic Media Network</s>\n",
            "1 <s> ባልና ሚስት ካንድ ወንዝ ይቀዳል...ዘንድሮ ጊዜው የናንተ ነው</s>\n",
            "0 <s> እንደ አንዳንድ እግርኳስ ተመልካች ባላንዶሩን ተሸልሞ ለማያውቅ ሰው እንዲሰጥ የመፈለግ ነገር ይታይባቸዋል ይሄ በግልህ ጥሩ ሆነህ ቡድንህን በመጥቀም የምታገኘው ሽልማት ነው ሊዮ ደሞ ከማንም በላይ ምርጥ ነበር</s>\n",
            "1 <s> : በጄነራል ከሊፋ ሀፍታር የሚመራው እና ትሪፖሊ ላይ የከተመው የሊቢያ ተፋላሚ ሀይሎች ተኩስ ለማቆም ተስማሙ፡፡ ሀገሪቱ ሙአማር ጋዳፊ እኤአ በ2011 ከተገደሉ ወዲህ ከግጭት ነጻ ሆና አታውቅም፡፡...</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDTkq3MlWN3q"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}